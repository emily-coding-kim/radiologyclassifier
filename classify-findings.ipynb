{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt for Google API\n",
    "def create_prompt(findings):\n",
    "    \"\"\"\n",
    "    Creates a prompt for the Google Generative AI API based on the findings\n",
    "    :param findings: The radiology findings to include in the prompt\n",
    "    :return: The formatted prompt string\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are an experienced veterinary clinician. I will provide you with a list of radiology findings written by a veterinary radiologist. \"\n",
    "        \"I will also provide a list of possible canine disease diagnoses. Mark each diagnosis Positive or Negative depending on your evaluation of the findings. \"\n",
    "        \"Please provide a detailed explanation for each diagnosis classification. Adhere to the following guidlines when classifying the findings:\\n\"\n",
    "        \"Disease Diagnoses:\\n\"\n",
    "        \"perihilar_infiltrate: Mark Positive if there is evidence of infiltrate in the perihilar region of the lungs.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of infiltrate in the perihilar, or say the perihilar region or lungs are normal.\\n\"\n",
    "        \"pneumonia: Mark Positive if the findings contain evidence of pneumonia or the following key words: alveolar pattern.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of pneumonia, or say the lungs are normal.\\n\"\n",
    "        \"bronchitis: Mark Positive if the findings contain evidence of bronchitis or the following key words: bronchial pattern, \"\n",
    "        \"bronchointerstitial pulmonary pattern, lobar bronchi narrowing, dynamic airway disease, bronchial wall thickening, \"\n",
    "        \"peribronchial cuffing, bronchial markings, increased bronchovascular markings, airway thickening, or prominent bronchi in the lungs.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of bronchitis, or say the bronchi is normal.\\n\"\n",
    "        \"interstitial: Mark Positive if the findings contain evidence of interstitial pattern in the lungs or the following key words: \"\n",
    "        \"interstitial pattern, interstitial pulmonary pattern, interstitial lung disease, interstitial markings, reticular pattern, \"\n",
    "        \"diffuse interstitial opacity, interstitial thickening, ground-glass opacities, linear opacities.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of interstitial pattern, or say the lungs are normal.\\n\"\n",
    "        \"diseased_lungs: Mark Positive if the findings contain evidence of the presence of any lung-related disease, diseased lungs, or the following key words: \"\n",
    "        \"diseased lungs, abnormal lung pattern, abnormal lung markings, abnormal lung opacity, abnormal lung structure, abnormal lung appearance, pulmonary disease, bronchointerstitial pattern.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of diseased lungs, or say the lungs are normal.\\n\"\n",
    "        \"hypo_plastic_trachea: Mark Positive if the findings contain evidence of hypoplastic trachea or the following key words: \"\n",
    "        \"hypoplastic trachea, tracheal hypoplasia, tracheal stenosis, tracheal collapse, tracheal narrowing, tracheal deformity, tracheal malformation, small trachea diameter.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of hypoplastic trachea, or say the trachea is normal.\\n\"\n",
    "        \"cardiomegaly: Mark Positive if the findings contain evidence of cardiomegaly or the following key words: \"\n",
    "        \"cardiomegaly, enlarged heart, heart enlargement, increased cardiac silhouette, heart size abnormality, heart volume increase, heart chamber enlargement.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of cardiomegaly, or say the heart is normal.\\n\"\n",
    "        \"pulmonary_nodules: Mark Positive if the findings contain evidence of pulmonary nodules or the following key words: \"\n",
    "        \"pulmonary nodules, lung nodules, pulmonary masses, lung masses, pulmonary lesions, lung lesions, pulmonary opacities, lung opacities.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of pulmonary nodules, or say the lungs are normal.\\n\"\n",
    "        \"pleural_effusion: Mark Positive if the findings contain evidence of pleural effusion or the following key words: \"\n",
    "        \"pleural effusion, fluid in the pleural space, pleural fluid accumulation, pleural fluid buildup, pleural fluid collection, pleural fluid presence, pleural fluid opacity.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of pleural effusion, or say the pleural space is normal.\\n\"\n",
    "        \"rtm: Mark Positive if the findings contain evidence or Redundant Tracheal Membrane (RTM) or the following key words: \"\n",
    "        \"Redundant Tracheal Membrane, RTM, tracheal membrane redundancy, tracheal membrane laxity, tracheal membrane abnormality, tracheal membrane deformity, tracheal membrane malformation.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of RTM, or say the trachea is normal.\\n\"\n",
    "        \"focal_caudodorsal_lung: Mark Positive if the findings contain evidence of focal caudodorsal lung disease or the following key words: \"\n",
    "        \"focal abnormalities in the caudodorsal lung region, focal caudodorsal lung disease, focal caudodorsal lung abnormalities, focal caudodorsal lung lesions, focal caudodorsal lung opacities, pulmonary bulla on caudal lung lobe.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of focal caudodorsal lung disease, or say the lungs are normal.\\n\"\n",
    "        \"focal_perihilar: Mark Positive if the findings contain evidence of focal perihilar lung disease or the following key words: \"\n",
    "        \"focal abnormalities in the perihilar lung region, focal perihilar lung disease, focal perihilar lung abnormalities, focal perihilar lung lesions, focal perihilar lung opacities.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of focal perihilar lung disease, or say the lungs are normal.\\n\"\n",
    "        \"pulmonary_hypoinflation: Mark Positive if the findings contain evidence of pulmonary hypoinflation or the following key words: \"\n",
    "        \"pulmonary hypoinflation, reduced lung volume, decreased lung inflation, hypoinflated lungs, underinflated lungs, hypoventilated lungs, pulmonary atelectasis.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of pulmonary hypoinflation, or say the lungs are normal.\\n\"\n",
    "        \"right_sided_cardiomegaly: Mark Positive if the findings contain evidence of right-sided cardiomegaly or the following key words: \"\n",
    "        \"right-sided cardiomegaly, right heart enlargement, right ventricular enlargement, right atrial enlargement, right-sided heart disease, right-sided heart failure.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of right-sided cardiomegaly, or say the heart is normal.\\n\"\n",
    "        \"pericardial_effusion: Mark Positive if the findings contain evidence of pericardial effusion or the following key words: \"\n",
    "        \"pericardial effusion, fluid in the pericardial sac, pericardial fluid accumulation, pericardial fluid buildup, pericardial fluid collection, pericardial fluid presence, pericardial fluid opacity, silhouette distortion in pericardial region.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of pericardial effusion, or say the pericardial sac is normal.\\n\"\n",
    "        \"bronchiectasis: Mark Positive if the findings contain evidence of bronchiectasis or the following key words: \"\n",
    "        \"bronchiectasis, bronchial dilation, bronchial widening, bronchial distortion, bronchial deformity, bronchial malformation, bronchial wall thickening, bronchial cysts, dilated airways, widened airways.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of bronchiectasis, or say the bronchi are normal.\\n\"\n",
    "        \"pulmonary_vessel_enlargement: Mark Positive if the findings contain evidence of pulmonary vessel enlargement or the following key words: \"\n",
    "        \"pulmonary vessel enlargement, enlarged pulmonary vessels, pulmonary artery enlargement, pulmonary vein enlargement, increased vascular markings, vascular congestion, vascular dilation.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of pulmonary vessel enlargement, or say the pulmonary vessels are normal.\\n\"\n",
    "        \"left_sided_cardiomegaly: Mark Positive if the findings contain evidence of left-sided cardiomegaly or the following key words: \"\n",
    "        \"left-sided cardiomegaly, left heart enlargement, left ventricular enlargement, left atrial enlargement, left-sided heart disease, left-sided heart failure.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of left-sided cardiomegaly, or say the heart is normal.\\n\"\n",
    "        \"thoracic_lymphadenopathy: Mark Positive if the findings contain evidence of thoracic lymphadenopathy or the following key words: \"\n",
    "        \"thoracic lymphadenopathy, intrathoracic lymphadenopathy, enlarged thoracic lymph nodes, mediastinal lymphadenopathy, hilar lymphadenopathy, thoracic lymph node enlargement, thoracic lymph node abnormalities.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of thoracic lymphadenopathy, or say the thoracic lymph nodes are normal.\\n\"\n",
    "        \"esophagitis: Mark Positive if the findings contain evidence of esophagitis or the following key words: \"\n",
    "        \"esophagitis, inflammation of the esophagus, esophageal inflammation, esophageal irritation, esophageal swelling, esophageal redness, esophageal lesions, esophageal dilation, gas distention, esophageal foreign body.\\n\"\n",
    "        \"    Mark Negative if the findings have no mention of these keywords, do not contain evidence of esophagitis, or say the esophagus is normal.\\n\"\n",
    "        \"vhs_v2: Mark Positive if the findings list the Vertebral Heart Score (VHS) as greater than 10.5.\\n\"\n",
    "        \"    Mark Negative if the findings list the VHS as less than or equal to 10.5, or do not mention the VHS at all.\\n\"\n",
    "        \"IMPORTANT: Return the results in JSON format that matches the ground truth structure. \"\n",
    "        \"Your response should contain ONLY the values for each disease classification (Positive, Negative, or Unknown). \"\n",
    "        \"Do NOT include explanations in this JSON output.\\n\\n\"\n",
    "        \n",
    "        \"Reference the findings:\\n\" + findings + \"\\n\\n\"\n",
    "        \"CRITICAL: Return ONLY raw JSON - no markdown, no code blocks, no explanations, no extra text.\\n\"\n",
    "        \"Your response must start with { and end with } and be valid JSON.\\n\\n\"\n",
    "        \"Return ONLY a JSON object in this EXACT JSON format (no markdown formatting):\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"perihilar_infiltrate\": \"Positive\",\\n'\n",
    "        '  \"pneumonia\": \"Negative\",\\n'\n",
    "        '  \"bronchitis\": \"Positive\",\\n'\n",
    "        '  \"interstitial\": \"Positive\",\\n'\n",
    "        '  \"diseased_lungs\": \"Positive\",\\n'\n",
    "        '  \"hypo_plastic_trachea\": \"Negative\",\\n'\n",
    "        '  \"cardiomegaly\": \"Negative\",\\n'\n",
    "        '  \"pulmonary_nodules\": \"Negative\",\\n'\n",
    "        '  \"pleural_effusion\": \"Negative\",\\n'\n",
    "        '  \"rtm\": \"Negative\",\\n'\n",
    "        '  \"focal_caudodorsal_lung\": \"Positive\",\\n'\n",
    "        '  \"focal_perihilar\": \"Negative\",\\n'\n",
    "        '  \"pulmonary_hypoinflation\": \"Negative\",\\n'\n",
    "        '  \"right_sided_cardiomegaly\": \"Negative\",\\n'\n",
    "        '  \"pericardial_effusion\": \"Negative\",\\n'\n",
    "        '  \"bronchiectasis\": \"Negative\",\\n'\n",
    "        '  \"pulmonary_vessel_enlargement\": \"Negative\",\\n'\n",
    "        '  \"left_sided_cardiomegaly\": \"Negative\",\\n'\n",
    "        '  \"thoracic_lymphadenopathy\": \"Negative\",\\n'\n",
    "        '  \"esophagitis\": \"Negative\",\\n'\n",
    "        '  \"vhs_v2\": \"Negative\"\\n'\n",
    "        \"}\\n\\n\"\n",
    "\n",
    "        \"Each value must be exactly 'Positive', 'Negative', or 'Unknown'. \"\n",
    "        \"Include all 21 disease classifications in the exact order shown above.\"\n",
    "        \"DO NOT include any other text, summaries, explanations, or formatting in your response.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_file(file_path):\n",
    "    \"\"\"\n",
    "    Opens and reads input file Excel document\n",
    "    :param file_path: Path to the input Excel file\n",
    "    :return: DataFrame containing the contents of the Excel file\n",
    "    \"\"\"\n",
    "    # check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Input file {file_path} does not exist\")\n",
    "    \n",
    "    # check if file is an Excel file\n",
    "    if not file_path.endswith(('.xls', '.xlsx')):\n",
    "        raise ValueError(f\"Input file {file_path} is not an Excel file\")\n",
    "\n",
    "    # try reading the Excel file and saving it as a DataFrame\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "    # raise a ValueError for any other exceptions that occur when reading the file \n",
    "    # with clearer error message\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading Excel file {file_path}: {e}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0829f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ground_truth_scores(excel_file_path, output_filename=None):\n",
    "    \"\"\"\n",
    "    Extract CaseID, Findings, and all 21 disease classifications from Excel file and convert to JSON format\n",
    "    :param excel_file_path: Path to the Excel file\n",
    "    :param output_filename: Optional custom filename for output JSON\n",
    "    :return: DataFrame with all data, and output filename\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = read_excel_file(excel_file_path)\n",
    "        print(f\"Loaded Excel file with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "        \n",
    "        # Define the 21 disease columns in the correct order\n",
    "        disease_columns = [\n",
    "            'perihilar_infiltrate', 'pneumonia', 'bronchitis', 'interstitial', 'diseased_lungs',\n",
    "            'hypo_plastic_trachea', 'cardiomegaly', 'pulmonary_nodules', 'pleural_effusion', 'rtm',\n",
    "            'focal_caudodorsal_lung', 'focal_perihilar', 'pulmonary_hypoinflation', 'right_sided_cardiomegaly',\n",
    "            'pericardial_effusion', 'bronchiectasis', 'pulmonary_vessel_enlargement', 'left_sided_cardiomegaly',\n",
    "            'thoracic_lymphadenopathy', 'esophagitis', 'vhs_v2'\n",
    "        ]\n",
    "        \n",
    "        # Check that all required columns exist\n",
    "        required_columns = ['CaseID', 'Findings'] + disease_columns\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"Error: Missing columns: {missing_columns}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Extract relevant columns and remove rows with no findings\n",
    "        extracted_df = df[required_columns].copy()\n",
    "        extracted_df = extracted_df.dropna(subset=['Findings'])  # Remove rows with no findings\n",
    "        \n",
    "        print(f\"Extracted {len(extracted_df)} cases with valid findings and disease classifications\")\n",
    "        \n",
    "        # Create JSON structure\n",
    "        json_data = {\n",
    "            \"source_file\": excel_file_path,\n",
    "            \"extraction_date\": datetime.datetime.now().isoformat(),\n",
    "            \"total_cases\": len(extracted_df),\n",
    "            \"disease_columns\": disease_columns,\n",
    "            \"cases\": []\n",
    "        }\n",
    "        \n",
    "        # Add each case with CaseID, findings, and all disease classifications\n",
    "        for index, row in extracted_df.iterrows():\n",
    "            case_data = {\n",
    "                \"case_id\": str(row['CaseID']).strip(),\n",
    "                \"findings\": str(row['Findings']).strip()\n",
    "            }\n",
    "            \n",
    "            # Add all disease classifications\n",
    "            for disease in disease_columns:\n",
    "                case_data[disease] = str(row[disease]).strip() if pd.notna(row[disease]) else \"Unknown\" # Positive/Negative value to str and removing whitespace (strip)\n",
    "            \n",
    "            json_data[\"cases\"].append(case_data)\n",
    "        \n",
    "        # Generate output filename if not provided\n",
    "        if output_filename is None:\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = f\"ground_truth_scores_{timestamp}.json\"\n",
    "        \n",
    "        # Write to JSON file\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(json_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"‚úì Successfully exported to: {output_filename}\")\n",
    "        \n",
    "        # Show sample of extracted data\n",
    "        print(f\"\\nSample of extracted data:\")\n",
    "        print(extracted_df[['CaseID', 'Findings'] + disease_columns[:5]].head(3))\n",
    "        \n",
    "        # Show disease distribution\n",
    "        print(f\"\\nDisease classification summary:\")\n",
    "        for disease in disease_columns[:5]:  # Show first 5 diseases\n",
    "            counts = extracted_df[disease].value_counts()\n",
    "            print(f\"  {disease}: {dict(counts)}\")\n",
    "        \n",
    "        return extracted_df, output_filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Excel file: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Process your Excel file with disease classifications\n",
    "excel_file_path = \"/Users/Emily/radiology-project/CLEANED-Emily-canine_thorax_scoring.xlsx\"\n",
    "complete_data, complete_json_filename = extract_ground_truth_scores(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de692ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for confusion matrix\n",
    "\n",
    "# Counts number of positive and negative cases for each disease in a JSON file\n",
    "def count_pos_neg(json_file, disease):\n",
    "    \"\"\"\n",
    "    Counts the number of positive and negative cases in the given JSON file for a given disease.\n",
    "    :param json_file: JSON file containing case data, either ground truth or ai scores\n",
    "    :param disease: Disease column to count positives and negatives for\n",
    "    :return: Dictionary with counts of positive and negative cases\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # extract disease_columns from the JSON data\n",
    "    if disease not in data['disease_columns']:\n",
    "        raise ValueError(f\"JSON file does not contain '{disease}' key\")\n",
    "\n",
    "    # Initialize counters\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "\n",
    "    # Count positives and negatives\n",
    "    for case in data['cases']:\n",
    "        if case[disease] == 'Positive':\n",
    "            pos_count += 1\n",
    "        elif case[disease] == 'Negative':\n",
    "            neg_count += 1\n",
    "\n",
    "    # Return counts\n",
    "    return {'Positive': pos_count, 'Negative': neg_count}\n",
    "# makes sure that all ai file cases are included in ground truth file\n",
    "def compare_check_files(ground_truth, ai_scores):\n",
    "    \"\"\"\n",
    "    Compares the ground truth and AI scores JSON files for consistency.\n",
    "    :param ground_truth: JSON file containing ground truth data\n",
    "    :param ai_scores: JSON file containing AI scores data\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # first, check if ai_scores has the same cases as ground_truth\n",
    "    if len(ground_truth['cases']) >= len(ai_scores['cases']):\n",
    "        raise ValueError(\"AI scores should have less than or equal to ground truth cases\")\n",
    "    # also make sure both have the same CaseIDs\n",
    "    ground_truth_ids = {case['case_id'] for case in ground_truth['cases']}\n",
    "    ai_scores_ids = {case['case_id'] for case in ai_scores['cases']}\n",
    "    if ground_truth_ids != ai_scores_ids:\n",
    "        raise ValueError(\"Ground truth and AI scores must have the same CaseIDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return Excel file, input file paths\n",
    "def create_confusion_matrix(ground_truth, ai_scores):\n",
    "    \"\"\"\n",
    "    Creates an Excel file containing confusion matrix from comparing ground truth and AI scores\n",
    "    :param ground_truth: JSON file containing ground truth data\n",
    "    :param ai_scores: JSON file containing AI scores data\n",
    "    :return: confusion matrix export as Excel file\n",
    "    \"\"\"\n",
    "\n",
    "    # compare the ground truth and ai_scores files\n",
    "    #compare_check_files(ground_truth, ai_scores)\n",
    "\n",
    "    # columns from Example Confusion Matrix\n",
    "    cols = [\n",
    "        'condition','tp_Positive','fn_Positive','tn_Positive','fp_Positive','Sensitivity','Specificity','Check',\n",
    "        'Positive Ground Truth','Negative Ground Truth','Ground Truth Check'\n",
    "    ]\n",
    "\n",
    "    # create df to hold confusion matrix data\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "   # Load JSON files if they are file paths (strings)\n",
    "    if isinstance(ground_truth, str):\n",
    "        with open(ground_truth, 'r') as f:\n",
    "            ground_truth_data = json.load(f)\n",
    "    else:\n",
    "        ground_truth_data = ground_truth\n",
    "        \n",
    "    if isinstance(ai_scores, str):\n",
    "        with open(ai_scores, 'r') as f:\n",
    "            ai_scores_data = json.load(f)\n",
    "    else:\n",
    "        ai_scores_data = ai_scores\n",
    "    \n",
    "    # Get disease columns from the ground truth data\n",
    "    disease_columns = ground_truth_data['disease_columns']\n",
    "    \n",
    "    # Process each disease (not 'condition' - that field doesn't exist)\n",
    "    for disease in disease_columns:\n",
    "        # Count ground truth cases for this disease\n",
    "        gt_counts = count_pos_neg(ground_truth, disease)\n",
    "        \n",
    "        # Initialize confusion matrix counters\n",
    "        tp = fp = tn = fn = 0\n",
    "        \n",
    "        # Calculate confusion matrix values for this disease\n",
    "        for ai_case in ai_scores_data['cases']:\n",
    "            # Find corresponding ground truth case\n",
    "            gt_case = next((c for c in ground_truth_data['cases'] if c['case_id'] == ai_case['case_id']), None)\n",
    "            if not gt_case:\n",
    "                continue\n",
    "                \n",
    "            ai_pred = ai_case[disease]\n",
    "            gt_true = gt_case[disease]\n",
    "            \n",
    "            if ai_pred == 'Positive' and gt_true == 'Positive':\n",
    "                tp += 1\n",
    "            elif ai_pred == 'Positive' and gt_true == 'Negative':\n",
    "                fp += 1\n",
    "            elif ai_pred == 'Negative' and gt_true == 'Positive':\n",
    "                fn += 1\n",
    "            elif ai_pred == 'Negative' and gt_true == 'Negative':\n",
    "                tn += 1\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        # Create row for this disease\n",
    "        row = {\n",
    "            'condition': disease,\n",
    "            'tp_Positive': tp,\n",
    "            'fn_Positive': fn,\n",
    "            'tn_Positive': tn,\n",
    "            'fp_Positive': fp,\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Specificity': specificity,\n",
    "            'Check': tp + fn + tn + fp,\n",
    "            'Positive Ground Truth': gt_counts['Positive'],\n",
    "            'Negative Ground Truth': gt_counts['Negative'],\n",
    "            'Ground Truth Check': gt_counts['Positive'] + gt_counts['Negative']\n",
    "        }\n",
    "        \n",
    "        # Use pd.concat instead of deprecated df.append\n",
    "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "    \n",
    "    # Export to Excel\n",
    "    df.to_excel('confusion_matrix.xlsx', index=False)\n",
    "    print(\"Confusion matrix created and saved as 'confusion_matrix.xlsx'\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a90a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def call_google_api(prompt, model='gemini-2.0-flash-lite', api_key=None):\n",
    "    \"\"\"\n",
    "    Calls the Google Generative AI API with the given prompt\n",
    "    :param prompt: The prompt to send to the Google Generative AI API\n",
    "    :param model: The model to use for the API call\n",
    "    :param api_key: The API key for authentication\n",
    "    :return: The response from the Google Generative AI API\n",
    "    \"\"\"\n",
    "    genai.configure(api_key=api_key)\n",
    "    model = genai.GenerativeModel(model)\n",
    "\n",
    "    generation_config = genai.types.GenerationConfig(\n",
    "        temperature=0.2  # adjust creativity (0.0-2.0)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt, generation_config=generation_config)\n",
    "        response_text = response.text\n",
    "        \n",
    "        # Clean up markdown formatting if present\n",
    "        if response_text.startswith('```json'):\n",
    "            # Remove ```json from start and ``` from end\n",
    "            response_text = response_text.replace('```json', '').replace('```', '').strip()\n",
    "        elif response_text.startswith('```'):\n",
    "            # Remove ``` from start and end\n",
    "            response_text = response_text.replace('```', '').strip()\n",
    "        if 'summary' in response_text or '**' in response_text or '***' in response_text:\n",
    "            # Remove any markdown formatting or summary text\n",
    "            response_text = response_text.replace('**', '').replace('***', '').replace('in summary', '').strip()\n",
    "        # Remove any text or reading/trailing whitespace after the final closing brace\n",
    "        if response_text.endswith('}'):\n",
    "            response_text = response_text[:response_text.rfind('}') + 1].strip()\n",
    "        \n",
    "        return response_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61274b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_scorings(ground_truth_json_path, api_key, model_type=\"google\", max_cases=None, output_filename=None):\n",
    "    \"\"\"\n",
    "    Process cases and create AI predictions in the same format as ground truth scores\n",
    "    :param ground_truth_json_path: Path to your ground truth JSON file with cases\n",
    "    :param api_key: API key for AI service\n",
    "    :param model_type: \"google\" or \"openai\"  \n",
    "    :param max_cases: Optional limit on number of cases to process\n",
    "    :param output_filename: Optional custom filename for AI predictions\n",
    "    :return: AI predictions in ground truth format\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üîç ai_scorings function called at {datetime.datetime.now()}\")\n",
    "\n",
    "    try:\n",
    "        # Read the ground truth JSON file\n",
    "        with open(ground_truth_json_path, 'r', encoding='utf-8') as f:\n",
    "            ground_truth_data = json.load(f)\n",
    "        \n",
    "        cases = ground_truth_data['cases']\n",
    "        if max_cases:\n",
    "            cases = cases[:max_cases]\n",
    "        \n",
    "        print(f\"üìä Processing {len(cases)} cases with AI...\")\n",
    "        \n",
    "        # Create AI predictions structure matching ground truth format\n",
    "        ai_predictions = {\n",
    "            \"source_file\": ground_truth_data['source_file'],\n",
    "            \"extraction_date\": datetime.datetime.now().isoformat(),\n",
    "            \"total_cases\": len(cases),\n",
    "            \"disease_columns\": ground_truth_data['disease_columns'],\n",
    "            \"model_used\": model_type,\n",
    "            \"cases\": []\n",
    "        }\n",
    "        \n",
    "        successful_predictions = 0\n",
    "        failed_predictions = 0\n",
    "        \n",
    "        for i, case in enumerate(cases, 1):\n",
    "            case_id = case['case_id']\n",
    "            findings_text = case['findings']\n",
    "\n",
    "            print(f\"üîÑ [AI_SCORINGS] Processing case {i}/{len(cases)} - CaseID: {case_id}\")\n",
    "\n",
    "            # Create prompt for this finding\n",
    "            prompt = create_prompt(findings_text)\n",
    "            \n",
    "            # Get AI response\n",
    "            print(f\"üì° Making API call for case {case_id}\")\n",
    "            response = call_google_api(prompt, api_key=api_key)\n",
    "            print(f\"‚úÖ API response received for case {case_id}\")\n",
    "            time.sleep(2)  # Sleep to avoid hitting API rate limits\n",
    "            \n",
    "            \n",
    "            # Try to parse AI response as JSON\n",
    "            try:\n",
    "                ai_classifications = json.loads(response)\n",
    "                \n",
    "                # Create case data in ground truth format\n",
    "                ai_case_data = {\n",
    "                    \"case_id\": case_id,\n",
    "                }\n",
    "                \n",
    "                # Add AI predictions for each disease\n",
    "                for disease in ground_truth_data['disease_columns']:\n",
    "                    if disease in ai_classifications:\n",
    "                        ai_case_data[disease] = ai_classifications[disease]\n",
    "                    else:\n",
    "                        ai_case_data[disease] = \"Unknown\"  # Fallback if AI didn't provide this disease\n",
    "                \n",
    "                ai_predictions[\"cases\"].append(ai_case_data)\n",
    "                successful_predictions += 1\n",
    "                print(f\"‚úÖ Successfully processed case {case_id}\")\n",
    "\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"  Warning: Failed to parse AI response for case {case_id}\")\n",
    "                print(f\"  Error: {e}\")\n",
    "                print(response)  # Print the raw response for debugging\n",
    "                \n",
    "                # Create case with all Unknown values\n",
    "                ai_case_data = {\n",
    "                    \"case_id\": case_id,\n",
    "                }\n",
    "                \n",
    "                # Set all diseases to Unknown for failed cases\n",
    "                for disease in ground_truth_data['disease_columns']:\n",
    "                    ai_case_data[disease] = \"Unknown\"\n",
    "                \n",
    "                ai_predictions[\"cases\"].append(ai_case_data)\n",
    "                failed_predictions += 1\n",
    "        \n",
    "        # Generate output filename if not provided\n",
    "        if output_filename is None:\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            model_name = model_type.lower()\n",
    "            output_filename = f\"ai_predictions_{model_name}_{timestamp}.json\"\n",
    "        \n",
    "        # Write AI predictions to JSON file\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(ai_predictions, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\n‚úì AI processing complete!\")\n",
    "        print(f\"‚úì Successful predictions: {successful_predictions}\")\n",
    "        print(f\"‚úì Failed predictions: {failed_predictions}\")\n",
    "        print(f\"‚úì AI predictions saved to: {output_filename}\")\n",
    "        \n",
    "        return ai_predictions, output_filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing cases: {e}\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = \"MY_API_KEY\"  # Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6b2f08c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ai_scorings function called at 2025-08-03 23:13:13.607924\n",
      "üìä Processing 50 cases with AI...\n",
      "üîÑ [AI_SCORINGS] Processing case 1/50 - CaseID: 2771776\n",
      "üì° Making API call for case 2771776\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "]\n",
      "‚úÖ API response received for case 2771776\n",
      "  Warning: Failed to parse AI response for case 2771776\n",
      "  Error: Expecting value: line 1 column 1 (char 0)\n",
      "Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "]\n",
      "üîÑ [AI_SCORINGS] Processing case 2/50 - CaseID: 2771700\n",
      "üì° Making API call for case 2771700\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 43\n",
      "}\n",
      "]\n",
      "‚úÖ API response received for case 2771700\n",
      "  Warning: Failed to parse AI response for case 2771700\n",
      "  Error: Expecting value: line 1 column 1 (char 0)\n",
      "Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 43\n",
      "}\n",
      "]\n",
      "üîÑ [AI_SCORINGS] Processing case 3/50 - CaseID: 2771679\n",
      "üì° Making API call for case 2771679\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "]\n",
      "‚úÖ API response received for case 2771679\n",
      "  Warning: Failed to parse AI response for case 2771679\n",
      "  Error: Expecting value: line 1 column 1 (char 0)\n",
      "Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "]\n",
      "üîÑ [AI_SCORINGS] Processing case 4/50 - CaseID: 2771608\n",
      "üì° Making API call for case 2771608\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 39\n",
      "}\n",
      "]\n",
      "‚úÖ API response received for case 2771608\n",
      "  Warning: Failed to parse AI response for case 2771608\n",
      "  Error: Expecting value: line 1 column 1 (char 0)\n",
      "Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 39\n",
      "}\n",
      "]\n",
      "üîÑ [AI_SCORINGS] Processing case 5/50 - CaseID: 2771606\n",
      "üì° Making API call for case 2771606\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "]\n",
      "‚úÖ API response received for case 2771606\n",
      "  Warning: Failed to parse AI response for case 2771606\n",
      "  Error: Expecting value: line 1 column 1 (char 0)\n",
      "Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "]\n",
      "üîÑ [AI_SCORINGS] Processing case 6/50 - CaseID: 2771599\n",
      "üì° Making API call for case 2771599\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "]\n",
      "‚úÖ API response received for case 2771599\n",
      "  Warning: Failed to parse AI response for case 2771599\n",
      "  Error: Expecting value: line 1 column 1 (char 0)\n",
      "Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "]\n",
      "üîÑ [AI_SCORINGS] Processing case 7/50 - CaseID: 2771467\n",
      "üì° Making API call for case 2771467\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 200\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "]\n",
      "‚úÖ API response received for case 2771467\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ai_scores, ai_json_filename = \u001b[43mai_scorings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mground_truth_json_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomplete_json_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmy_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or \"openai\"\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_cases\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Process all cases\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Auto-generate filename\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mai_scorings\u001b[39m\u001b[34m(ground_truth_json_path, api_key, model_type, max_cases, output_filename)\u001b[39m\n\u001b[32m     49\u001b[39m response = call_google_api(prompt, api_key=api_key)\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ API response received for case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Sleep to avoid hitting API rate limits\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Try to parse AI response as JSON\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ai_scores, ai_json_filename = ai_scorings(\n",
    "    ground_truth_json_path=complete_json_filename,\n",
    "    api_key=my_api_key,\n",
    "    model_type=\"google\",  # or \"openai\"\n",
    "    max_cases=None,  # Process all cases\n",
    "    output_filename=None  # Auto-generate filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0589fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_confusion_matrix(ground_truth=complete_json_filename, ai_scores=ai_json_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
